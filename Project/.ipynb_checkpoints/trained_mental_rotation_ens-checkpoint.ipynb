{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the trained weights in an ensemble of neurons\n",
    "- On the function points branch of nengo\n",
    "- On the vision branch of nengo_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nengo\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from nengo_extras.data import load_mnist\n",
    "from nengo_extras.vision import Gabor, Mask\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- load the data\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
    "\n",
    "X_train = 2 * X_train - 1  # normalize to -1 to 1\n",
    "X_test = 2 * X_test - 1  # normalize to -1 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit is represented by a one hot vector where the index of the 1 represents the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = np.diag([1]*10)\n",
    "\n",
    "ZERO = temp[0]\n",
    "ONE =  temp[1]\n",
    "TWO =  temp[2]\n",
    "THREE= temp[3]\n",
    "FOUR = temp[4]\n",
    "FIVE = temp[5]\n",
    "SIX =  temp[6]\n",
    "SEVEN =temp[7]\n",
    "EIGHT= temp[8]\n",
    "NINE = temp[9]\n",
    "\n",
    "labels =[ZERO,ONE,TWO,THREE,FOUR,FIVE,SIX,SEVEN,EIGHT,NINE]\n",
    "\n",
    "dim =28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved weight matrices that were created by trainging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_weights = cPickle.load(open(\"label_weights5000.p\", \"rb\"))\n",
    "activity_to_img_weights = cPickle.load(open(\"activity_to_img_weights5000.p\", \"rb\"))\n",
    "rotated_after_encoder_weights =  cPickle.load(open(\"rotated_after_encoder_weights5000.p\", \"r\"))\n",
    "#rotated_after_encoder_weights_5000 =  cPickle.load(open(\"rotated_after_encoder_weights_5000.p\", \"r\"))\n",
    "\n",
    "rotation_weights = cPickle.load(open(\"rotation_weights5000.p\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network where the mental imagery and rotation occurs\n",
    "- The state, seed and ensemble parameters (including encoders) must all be the same for the saved weight matrices to work\n",
    "- The number of neurons (n_hid) must be the same as was used for training\n",
    "- The input must be shown for a short period of time to be able to view the rotation\n",
    "- The recurrent connection must be from the neurons because the weight matices were trained on the neuron activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(9)\n",
    "n_hid = 5000\n",
    "model = nengo.Network(seed=3)\n",
    "with model:\n",
    "    #Stimulus only shows for brief period of time\n",
    "    stim = nengo.Node(lambda t: ONE if t < 0.1 else 0) #nengo.processes.PresentInput(labels,1))#\n",
    "    \n",
    "    ens_params = dict(\n",
    "        eval_points=X_train,\n",
    "        neuron_type=nengo.LIF(), #Why not use LIF?\n",
    "        intercepts=nengo.dists.Choice([-0.5]),\n",
    "        max_rates=nengo.dists.Choice([100]),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # linear filter used for edge detection as encoders, more plausible for human visual system\n",
    "    encoders = Gabor().generate(n_hid, (11, 11), rng=rng)\n",
    "    encoders = Mask((28, 28)).populate(encoders, rng=rng, flatten=True)\n",
    "\n",
    "\n",
    "    ens = nengo.Ensemble(n_hid, dim**2, seed=3, encoders=encoders, **ens_params)\n",
    "    \n",
    "    #Recurrent connection on the neurons of the ensemble to perform the rotation\n",
    "    nengo.Connection(ens.neurons, ens.neurons, transform = rotated_after_encoder_weights.T, synapse=0.2)      \n",
    "\n",
    "    #Connect stimulus to ensemble, transform using learned weight matrices\n",
    "    nengo.Connection(stim, ens, transform = np.dot(label_weights,activity_to_img_weights).T, synapse=0.1)\n",
    "    \n",
    "    #Collect output, use synapse for smoothing\n",
    "    probe = nengo.Probe(ens.neurons,synapse=0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is not part of the brain model, it is used to view the output for the ensemble\n",
    "Since it's probing the neurons themselves, the output must be transformed from neuron activity to visual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Animation for Probe output'''\n",
    "fig = plt.figure()\n",
    "\n",
    "output_acts = []\n",
    "for act in sim.data[probe]:\n",
    "    output_acts.append(np.dot(act,activity_to_img_weights))\n",
    "\n",
    "def updatefig(i):\n",
    "    im = pylab.imshow(np.reshape(output_acts[i],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'),animated=True)\n",
    "    \n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig, interval=0.1, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the probe's output if it takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The filename includes the number of neurons and which digit is being rotated\n",
    "filename = \"mental_rotation_output_ONE_\"  + str(n_hid) + \".p\"\n",
    "cPickle.dump(sim.data[probe], open( filename , \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(testing,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get image\n",
    "testing = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=testing)\n",
    "\n",
    "#Get rotated encoder outputs\n",
    "testing_rotate = np.dot(testing_act,rotated_after_encoder_weights)\n",
    "\n",
    "#Get activities\n",
    "testing_rotate = ens.neuron_type.rates(testing_rotate, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "for i in range(5):\n",
    "    testing_rotate = np.dot(testing_rotate,rotated_after_encoder_weights)\n",
    "    testing_rotate = ens.neuron_type.rates(testing_rotate, sim.data[ens].gain, sim.data[ens].bias)\n",
    "\n",
    "\n",
    "#testing_rotate = np.dot(testing_rotate,rotation_weights)\n",
    "\n",
    "testing_rotate = np.dot(testing_rotate,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_rotate,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(121)\n",
    "pylab.imshow(np.reshape(X_train[0],(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "#Get activity of image\n",
    "_, testing_act = nengo.utils.ensemble.tuning_curves(ens, sim, inputs=X_train[0])\n",
    "\n",
    "testing_rotate = np.dot(testing_act,activity_to_img_weights)\n",
    "\n",
    "plt.subplot(122)\n",
    "pylab.imshow(np.reshape(testing_rotate,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letterO = np.dot(ZERO,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(161)\n",
    "pylab.imshow(np.reshape(letterO,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterL = np.dot(SEVEN,label_weights)\n",
    "for _ in range(30):\n",
    "    letterL = np.dot(letterL,rotation_weights)\n",
    "letterL = np.dot(letterL,activity_to_img_weights)\n",
    "plt.subplot(162)\n",
    "pylab.imshow(np.reshape(letterL,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterI = np.dot(ONE,np.dot(label_weights,activity_to_img_weights))\n",
    "plt.subplot(163)\n",
    "pylab.imshow(np.reshape(letterI,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "plt.subplot(165)\n",
    "pylab.imshow(np.reshape(letterI,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterV = np.dot(SEVEN,label_weights)\n",
    "for _ in range(40):\n",
    "    letterV = np.dot(letterV,rotation_weights)\n",
    "letterV = np.dot(letterV,activity_to_img_weights)\n",
    "plt.subplot(164)\n",
    "pylab.imshow(np.reshape(letterV,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "letterA = np.dot(SEVEN,label_weights)\n",
    "for _ in range(10):\n",
    "    letterA = np.dot(letterA,rotation_weights)\n",
    "letterA = np.dot(letterA,activity_to_img_weights)\n",
    "plt.subplot(166)\n",
    "pylab.imshow(np.reshape(letterA,(dim, dim), 'F').T, cmap=plt.get_cmap('Greys_r'))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
